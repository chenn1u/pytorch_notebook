{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PyTorch 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Pytorch 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 pytorch简介\n",
    "* pytorch 是深度学习框架和科学计算包\n",
    "* pytorch之所以可以进行科学计算是因为它是一个张量库并且有相关的张量运算\n",
    "* pytorch和numpy有很强的互操作性，原因：1.张量和数组具有相似性； 2.pytorch的torch.tensor对象是由numpy的ndarray创建的，它们共享内存；\n",
    "* pytorch 张量运算可在GPU上运行；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 pytorch简史\n",
    "* pytorch的前身是torch，torch是基于lua语言(该语言晦涩难懂且生态系统很小)；\n",
    "* pytorch的发起者是facebook的研究员Soumith Chintala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 pytorch 库\n",
    "* torch: 包含所有torch包和tensor库的顶级包\n",
    "* troch.nn: 是用于建立神经网络的包，它包含类和模块，如layer,weight和forward function\n",
    "* torch.autograd: 支持张量的导数运算，负责优化神经网络\n",
    "* torch.nn.function: 访问损失函数的API\n",
    "* torch.optim: 访问优化器 (SGD,ADAM...)\n",
    "* torch.utils: 包含数据集和数据加载器的实用程序类\n",
    "* torchvision: 访问流行的数据集、计算机视觉中的模型框架及图像转换\n",
    "* 所有深度学习框架都有两个特性:张量库和计算导数的包(在pytorch中是torch和torch.autograd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 pytorch的特点\n",
    "* pytorch is modern, pythonic and thin design\n",
    "* pytorch is a python extension\n",
    "* pytorch的简单性使其具有更长的寿命\n",
    "* pytorch是研究中首选框架的原因：pytorch的计算图是动态的，而其他框架通常是静态的，许多深度学习领域的前沿研究都需要动态图或从动态图中获益\n",
    "* 计算图是用于描绘神经网络中张量的函数操作，通常用于计算优化神经网络权重所需的导数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pytorch的安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 pytorch安装\n",
    "* step1: 下载并安装[anaconda](https://www.anaconda.com/distribution/)\n",
    "* step2：进入[pytorch官网](https://pytorch.org/), 选择相应的配置，会出现相应的命令行，复制在终端并运行，即可安装；\n",
    "* 不需要自己额外安装Cuda，安装pytorch时Cuda会自动安装；\n",
    "* Cudnn是专门用于神经网络的包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 pytorch安装验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 CUDA简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 GPU的运算\n",
    "* 最适合GPU的运算是可以并行完成的运算\n",
    "* 并行计算：一个特定的计算被分解成独立的可以同时进行的很小的计算，得到的计算被重新组合和同步，以形成原始较大的计算结果\n",
    "* 一个更大的计算可以被分解的任务的数量取决于硬件上的核数（CPU通常是4或16核，而GPU可以有成千上万个核，故GPU可以大大提升运算速度）\n",
    "* 核是指在给定处理器中进行计算的单元\n",
    "* 并行计算是使用GPU来完成的 => 最适合GPU的任务是可以并行完成的任务\n",
    "* 为什么GPU在深度学习中能够如此广泛的使用？——答：因为神经网络是易并行的(embarrassing parallel),即：很容易就能够将任务分解成一组独立的小任务；神经网络的很多计算都可以很容易地分解成更小的相互独立的计算，这使得GPU在深度学习任务中非常有用；\n",
    "* 一个卷积核对一张图像进行卷积的每个运算是独立且相继发生的，故可将其分成一个个小任务，使用GPU加速运算；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Cudnn\n",
    "* 用于神经网络的包\n",
    "* 在安装pytorch时已自带"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 using Cuda with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([1, 2, 3])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.cuda()\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GPU的运算速度比CPU快，为什么不直接在GPU上进行所有运算？ ——答: 将数据从CPU移到GPU代价高昂，如果任务本身较小较简单，这样做反而会让运算速度变慢；GPU对于能够分解成很多小任务的计算效果更好；\n",
    "\n",
    "* GPU计算堆栈的形式：GPU是底层硬件，Cuda是GPU的顶端软件框架，在Cuda的顶部是Cudnn；"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
