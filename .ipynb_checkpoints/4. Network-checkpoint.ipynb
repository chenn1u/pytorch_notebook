{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 CNN构建及网络参数的使用\n",
    "在Network类中，我们定义了两个卷积层和三个线性层；两个主要的部分封装在其中，即前向函数的定义和权重张量；每个层中权重张量包含了随着我们的网络在训练过程中学习而更新的权重值（这就是在网络类中将层定义为类属性的原因）；在Module类中，pytorch可以跟踪每一层的权重张量，由于我们在创建Network类时扩展了Module类，也就自动继承了该功能。\n",
    "- Parameter和Argument的区别：\n",
    "    - Parameter在函数定义中使用，可将其看作是占位符；(形参)\n",
    "    - Argument是当函数被调用时传递给函数的实际值；（实参）\n",
    "- Parameter的两种类型：\n",
    "    - 1.Hyperparameters:其值是手动和任意确定的；要构建神经网络：kernel_size, out_channels, out_features都需要手动选择\n",
    "    - 2.Data dependent Hyperparameters:其值是依赖于数据的参数\n",
    "        - 该参数位于网络的开始或末端，即第一个卷积层的输入通道和最后一个卷积层的输出特征图\n",
    "        - 第一个卷积层的输入通道依赖于构成训练集的图像内部的彩色通道的数量（灰度图像是1，彩色图像是3）\n",
    "        - 输出层的输出特征依赖于训练集中类的数量（fashion-MNIST数据集中的类型为10，则输出层的out_features=10）\n",
    "        - 通常情况下，一层的输入是上一层的输出（即：卷积层中所有输入通道和线性层中的输入特征都依赖于上一层的数据）\n",
    "- 当张量从卷积层传入线性层时，张量必须是flatten的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Parameter     |     Description      |\n",
    "|:----------------------|:-------------------------|\n",
    "|kernel_size| 设置滤波器的大小；滤波器的数量就是输出通道数|\n",
    "|out_channels| 设置滤波器的数量，即为输出通道数|\n",
    "|out_features| 设置输出张量的大小|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) conv layer1\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (3) conv layer2\n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) linear layer1\n",
    "        t = t.flatten(start_dim=1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        \n",
    "        # (5) linear layer2\n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = Network()\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 CNN的权重\n",
    "* 可学习参数：是在训练过程中学习的参数，初值是选择的任意值，其值在网络学习的过程中以迭代的方式进行更新\n",
    "* 说网络在学习是指：网络在学习参数的适合的值，适合的值就是能使损失函数最小化的值\n",
    "* 可学习的参数是网络的权重，存在于每一层中\n",
    "* 当我们扩展类的时候，我们会得到它的所有功能，为了得到它，我们可以添加额外的功能，也可覆盖现有的功能\n",
    "* 在python中，所有特殊的面向对象的方法通常都有前双下划线和后双下划线（__init__, __repr__）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.1131, -0.1885,  0.0338,  0.1422,  0.0272],\n",
       "          [-0.0711, -0.0092,  0.0719, -0.1647,  0.1972],\n",
       "          [ 0.1608,  0.0520,  0.0904, -0.1318, -0.0272],\n",
       "          [-0.1267, -0.1063,  0.1072,  0.1634,  0.1675],\n",
       "          [ 0.1182, -0.0100, -0.0458,  0.1479, -0.0369]]],\n",
       "\n",
       "\n",
       "        [[[-0.0973,  0.0234,  0.1178,  0.1783, -0.1630],\n",
       "          [ 0.1498, -0.1367, -0.0878,  0.0890, -0.0679],\n",
       "          [ 0.0222, -0.1330, -0.0074, -0.1481, -0.0741],\n",
       "          [ 0.1086, -0.1967, -0.1706, -0.0103,  0.0219],\n",
       "          [ 0.1799,  0.1173,  0.0560, -0.1916,  0.0922]]],\n",
       "\n",
       "\n",
       "        [[[-0.0108,  0.1815, -0.0545, -0.0817, -0.0975],\n",
       "          [-0.0986, -0.1424,  0.0542, -0.0620, -0.1166],\n",
       "          [ 0.1297, -0.0579, -0.1588, -0.1736, -0.1321],\n",
       "          [-0.1871,  0.1328,  0.1452,  0.1526, -0.1546],\n",
       "          [-0.1944, -0.1146,  0.0055,  0.0473, -0.0308]]],\n",
       "\n",
       "\n",
       "        [[[-0.1284,  0.0007, -0.1176, -0.1789, -0.0312],\n",
       "          [ 0.0440, -0.0423,  0.0432, -0.0043,  0.1099],\n",
       "          [ 0.0941,  0.1135, -0.1707,  0.0692,  0.1505],\n",
       "          [ 0.0235, -0.0089, -0.1154, -0.1011,  0.0358],\n",
       "          [ 0.1781,  0.1718, -0.0657,  0.0666,  0.1377]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0204, -0.1681,  0.0760, -0.1283, -0.1709],\n",
       "          [ 0.0393,  0.1854, -0.0741, -0.1572,  0.1105],\n",
       "          [ 0.1739, -0.0852,  0.1613, -0.1716,  0.0949],\n",
       "          [-0.0164,  0.0092,  0.1814, -0.0804, -0.0721],\n",
       "          [-0.0268,  0.0843, -0.1862,  0.1333,  0.0970]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0630, -0.0169, -0.1698, -0.0337, -0.1526],\n",
       "          [ 0.1536, -0.1254, -0.1702, -0.1194,  0.0696],\n",
       "          [-0.0920, -0.1781, -0.1945,  0.0736, -0.0703],\n",
       "          [-0.0410,  0.1272,  0.0369,  0.0277, -0.0955],\n",
       "          [ 0.0309,  0.1055, -0.1437, -0.0089, -0.1845]]]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
